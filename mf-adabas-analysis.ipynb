{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install openai\n",
    "%pip install requests \n",
    "import openai\n",
    "import requests\n",
    "openai.api_key=\"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\"  # Replace this with your API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of the function to get MF source code\n",
    "def get_source_code(fine_name=\"program.txt\"):\n",
    "\n",
    "    url = \"https://raw.githubusercontent.com/SoftwareAG/adabas-natural-code-samples/main/Last%20Day%20of%20a%20Month/program.txt\"\n",
    "\n",
    "    return requests.get(url).text\n",
    "\n",
    "\n",
    "# Function to be passed to OpenAI API\n",
    "functions = [\n",
    "    {\n",
    "        \"name\": \"get_source_code\",\n",
    "        \"description\": \"get an adabas nantural source code\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"file_name\": {\n",
    "                    \"type\": \"string\"\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Standard GPT model cannot answer a question about a specific function.\n",
    "#### GPT: \"Without the actual content of the source code in program.txt, it is not possible to determine what it does. \""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'm sorry, but as an AI language model, I cannot access or view specific source code files like \"program.txt\" or any other external file. If you provide the contents of the source code, I can help you understand what it does.\n"
     ]
    }
   ],
   "source": [
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"\"\"\n",
    "        What does this source code do - program.txt?\n",
    "    \"\"\"}]\n",
    "\n",
    "response = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo-0613\",\n",
    "    messages=messages\n",
    "    )\n",
    "\n",
    "print(response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### If we add a source code with the question, GPT is able to answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided source code is a program written in an unidentified programming language. It demonstrates how to take a given source date (either in alpha or date format) and derive the last day of the preceding month.\n",
      "\n",
      "The program consists of several steps:\n",
      "\n",
      "1. It defines local data variables including the source date in alpha format (#DATE-ALPHA-SOURCE) and date format (#DATE-D-SOURCE).\n",
      "\n",
      "2. It includes two additional files: AATITLER and AASETC.\n",
      "\n",
      "3. The program then proceeds with two scenarios: one where the source date is in date format and another where it is in alpha format.\n",
      "\n",
      "4. For the date format scenario, the program converts the source date to alpha format and extracts the day of the month (#DAYS-N). It then calculates the intermediate date by subtracting #DAYS-N from the source date and adding 1. Finally, it calculates the target date by subtracting 1 from the intermediate date. The three dates (source, intermediate, and target) are written to the output.\n",
      "\n",
      "5. The program then demonstrates that the intermediate date calculation can be combined with the target date calculation if the intermediate date is not needed.\n",
      "\n",
      "6. For the alpha format scenario, the program copies the source date to the target date variable and sets the day of the month to '01'. It then converts the target date from alpha to date format and subtracts 1 to get the desired target date. The source date in alpha format and the target date are written to the output.\n",
      "\n",
      "7. If an alpha output is required, the target date is converted back to alpha format, and both the source date and the target date in alpha format are written to the output.\n",
      "\n",
      "After the program code, there is an example output of the program, showing the values of the variables after execution.\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "messages = [{\n",
    "    \"role\": \"user\", \n",
    "    \"content\": \"\"\"\n",
    "         What does this source code do - program.txt?\n",
    "    \"\"\"}]\n",
    "\n",
    "# Step 1: call the API\n",
    "response = openai.ChatCompletion.create(\n",
    "        model=\"gpt-3.5-turbo-0613\",\n",
    "        messages=messages, \n",
    "        functions=functions,   # <---- this is the new part. Pass the functions to the API.\n",
    "        function_call=\"auto\",\n",
    "        )\n",
    "\n",
    "response_message = response[\"choices\"][0][\"message\"]\n",
    "\n",
    "# Step 2: check if GPT wanted to call a function\n",
    "if response_message.get(\"function_call\"):\n",
    "        # Step 3: call the function\n",
    "        # Note: the JSON response may not always be valid; be sure to handle errors\n",
    "        available_functions = {\n",
    "                \"get_source_code\": get_source_code,\n",
    "        }  # only one function in this example, but you can have multiple\n",
    "        function_name = response_message[\"function_call\"][\"name\"]\n",
    "        fuction_to_call = available_functions[function_name]\n",
    "        function_args = json.loads(response_message[\"function_call\"][\"arguments\"])\n",
    "        function_response = fuction_to_call(\n",
    "                fine_name=function_args.get(\"file_name\")\n",
    "        )\n",
    "\n",
    "        # Step 4: send the info on the function call and function response to GPT\n",
    "        messages.append(response_message)  # extend conversation with assistant's reply\n",
    "        messages.append(\n",
    "                {\n",
    "                \"role\": \"function\",\n",
    "                \"name\": function_name,\n",
    "                \"content\": function_response,\n",
    "                }\n",
    "        )  # extend conversation with function response\n",
    "        second_response = openai.ChatCompletion.create(\n",
    "                model=\"gpt-3.5-turbo-0613\",\n",
    "                messages=messages,\n",
    "        )  # get a new response from GPT where it can see the function response\n",
    "        print(second_response[\"choices\"][0][\"message\"][\"content\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
