{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1KxMxn4BH-oyKFRMBUc7r0iR_4ipGLBK9","timestamp":1690122903401}],"authorship_tag":"ABX9TyNTD5SagY1hU4p8uc3TwFZu"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"FR2XWohKKa35"},"outputs":[],"source":["import os\n","import faiss\n","import openai\n","import langchain  # You need to install the langchain library first\n","from langchain.document_loaders import TextLoader\n","from langchain.embeddings.openai import OpenAIEmbeddings\n","from langchain.text_splitter import CharacterTextSplitter\n","from langchain.vectorstores import FAISS\n","\n","# Load the document, split it into chunks, embed each chunk and load it into the vector store.\n","\n","# Initialize OpenAI API (You need to set your API key here)\n","openai.api_key = \"YOUR_OPENAI_API_KEY\"\n","\n","# Initialize LangChain (Replace \"config_path\" with the path to your config file)\n","lc = langchain.LangChain(config_path=\"config_path\")\n","\n","# Initialize Faiss index\n","d = 768  # Dimension of the embeddings (Assuming GPT-3.5 produces 768-dimensional embeddings)\n","index = faiss.IndexFlatL2(d)\n","\n","# Function to read log data from the folder\n","def read_log_data(folder_path):\n","    log_data = []\n","    db_documents = []\n","    for filename in os.listdir(folder_path):\n","        if filename.endswith(\".log\"):\n","            file_path_name = os.path.join(folder_path, filename)\n","            raw_documents = TextLoader(file_path_name).load()\n","            text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n","            documents = text_splitter.split_documents(raw_documents)\n","    db = FAISS.from_documents(db_documents, OpenAIEmbeddings())\n","    return db\n","\n","\n","\n","folder_path = \"path_to_log_folder\"\n","db = read_and_process_data(folder_path)\n","query = \"What did the president say about Ketanji Brown Jackson\"\n","docs = db.similarity_search(query)\n","print(docs[0].page_content)\n","\n","EMBEDDING_MODEL = \"text-embedding-ada-002\"\n","GPT_MODEL = \"gpt-3.5-turbo\"\n","\n","query = 'Which athletes won the gold medal in curling at the 2022 Winter Olympics?'\n","\n","response = openai.ChatCompletion.create(\n","    messages=[\n","        {'role': 'system', 'content': 'You answer questions about the 2022 Winter Olympics.'},\n","        {'role': 'user', 'content': query},\n","    ],\n","    model=GPT_MODEL,\n","    temperature=0,\n",")\n","\n","print(response['choices'][0]['message']['content'])\n","\n"]},{"cell_type":"code","source":["reference_link-https://python.langchain.com/docs/modules/data_connection/vectorstores/integrations/faiss\n","https://github.com/openai/openai-cookbook/blob/main/examples/Question_answering_using_embeddings.ipynb"],"metadata":{"id":"zwRJkqOSKfYX"},"execution_count":null,"outputs":[]}]}